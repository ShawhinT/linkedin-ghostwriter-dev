{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b113316b-b62a-44dc-b843-2c0687be4f39",
   "metadata": {},
   "source": [
    "# LinkedIn Ghostwriter Prompt Optimization\n",
    "\n",
    "Code authored by: Shaw Talebi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b36b5-0599-46bf-a774-c6da9cdfbce2",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006d6900-6055-4fc3-8582-5bb12a4ee723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from utils.evals import eval_voice, eval_em_dashes\n",
    "from utils.experiments import init_experiment, generate_posts, run_evals, compute_results, compute_summary\n",
    "from utils import evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb5221-35e6-4a4f-bde5-12da123f8ba7",
   "metadata": {},
   "source": [
    "### init experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f8552b-13a9-4d56-a75f-0034c6381312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "input_path = \"data/inputs/inputs-shaw-test.csv\"\n",
    "model_name = \"gpt-4.1-2025-04-14\"\n",
    "num_posts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b09b745-4007-4cac-8c5f-6e247b6ab898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Experiment initialized: experiments/2025_06_19-prompt_v1-inputs_shaw_test-num_posts_10\n",
      "\n",
      "Config YAML content:\n",
      "name: 2025_06_19-prompt_v1-inputs_shaw_test-num_posts_10\n",
      "date: '2025-06-19'\n",
      "prompt_name: prompt-v1\n",
      "prompt_path: prompts/ghostwriter/prompt-v1.md\n",
      "model:\n",
      "  name: gpt-4.1-2025-04-14\n",
      "  temperature: 1\n",
      "inputs:\n",
      "  num_posts: 10\n",
      "  total_posts: 10\n",
      "  input_path: data/inputs/inputs-shaw-test.csv\n",
      "evals:\n",
      "  eval_em_dashes:\n",
      "    description: Evaluates the number of em-dashes in a post.\n",
      "    type: code-based\n",
      "    args: null\n",
      "  eval_voice:\n",
      "    description: Evaluates the voice of a LinkedIn post using an LLM Judge.\n",
      "    type: LLM-based\n",
      "    args:\n",
      "      prompt_path: prompts/judge-voice/prompt-v7.md\n",
      "      model_name: gpt-4.1-2025-04-14\n",
      "notes: ''\n",
      "\n",
      "\n",
      " To make changes, edit the config.yaml file directly.\n",
      "Generating post 1/10...\n",
      "Saved: post-001.json\n",
      "Generating post 2/10...\n",
      "Saved: post-002.json\n",
      "Generating post 3/10...\n",
      "Saved: post-003.json\n",
      "Generating post 4/10...\n",
      "Saved: post-004.json\n",
      "Generating post 5/10...\n",
      "Saved: post-005.json\n",
      "Generating post 6/10...\n",
      "Saved: post-006.json\n",
      "Generating post 7/10...\n",
      "Saved: post-007.json\n",
      "Generating post 8/10...\n",
      "Saved: post-008.json\n",
      "Generating post 9/10...\n",
      "Saved: post-009.json\n",
      "Generating post 10/10...\n",
      "Saved: post-010.json\n",
      "All 10 posts generated and saved to experiments/2025_06_19-prompt_v1-inputs_shaw_test-num_posts_10/posts/\n",
      "Running eval: eval_em_dashes\n",
      "Running eval: eval_em_dashes for post: post-004.json\n",
      "Running eval: eval_em_dashes for post: post-008.json\n",
      "Running eval: eval_em_dashes for post: post-009.json\n",
      "Running eval: eval_em_dashes for post: post-005.json\n",
      "Running eval: eval_em_dashes for post: post-002.json\n",
      "Running eval: eval_em_dashes for post: post-003.json\n",
      "Running eval: eval_em_dashes for post: post-001.json\n",
      "Running eval: eval_em_dashes for post: post-006.json\n",
      "Running eval: eval_em_dashes for post: post-010.json\n",
      "Running eval: eval_em_dashes for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v1-inputs_shaw_test-num_posts_10/evals/eval_em_dashes.csv\n",
      "Running eval: eval_voice\n",
      "Running eval: eval_voice for post: post-004.json\n",
      "Running eval: eval_voice for post: post-008.json\n",
      "Running eval: eval_voice for post: post-009.json\n",
      "Running eval: eval_voice for post: post-005.json\n",
      "Running eval: eval_voice for post: post-002.json\n",
      "Running eval: eval_voice for post: post-003.json\n",
      "Running eval: eval_voice for post: post-001.json\n",
      "Running eval: eval_voice for post: post-006.json\n",
      "Running eval: eval_voice for post: post-010.json\n",
      "Running eval: eval_voice for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v1-inputs_shaw_test-num_posts_10/evals/eval_voice.csv\n",
      "Computing results for eval_em_dashes.csv\n",
      "Computing results for eval_voice.csv\n",
      "Results saved to experiments/2025_06_19-prompt_v1-inputs_shaw_test-num_posts_10/results.json\n",
      "Summary saved to summary.csv\n",
      "-------------------------------------------------------------------------\n",
      "Experiment initialized: experiments/2025_06_19-prompt_v2-inputs_shaw_test-num_posts_10\n",
      "\n",
      "Config YAML content:\n",
      "name: 2025_06_19-prompt_v2-inputs_shaw_test-num_posts_10\n",
      "date: '2025-06-19'\n",
      "prompt_name: prompt-v2\n",
      "prompt_path: prompts/ghostwriter/prompt-v2.md\n",
      "model:\n",
      "  name: gpt-4.1-2025-04-14\n",
      "  temperature: 1\n",
      "inputs:\n",
      "  num_posts: 10\n",
      "  total_posts: 10\n",
      "  input_path: data/inputs/inputs-shaw-test.csv\n",
      "evals:\n",
      "  eval_em_dashes:\n",
      "    description: Evaluates the number of em-dashes in a post.\n",
      "    type: code-based\n",
      "    args: null\n",
      "  eval_voice:\n",
      "    description: Evaluates the voice of a LinkedIn post using an LLM Judge.\n",
      "    type: LLM-based\n",
      "    args:\n",
      "      prompt_path: prompts/judge-voice/prompt-v7.md\n",
      "      model_name: gpt-4.1-2025-04-14\n",
      "notes: ''\n",
      "\n",
      "\n",
      " To make changes, edit the config.yaml file directly.\n",
      "Generating post 1/10...\n",
      "Saved: post-001.json\n",
      "Generating post 2/10...\n",
      "Saved: post-002.json\n",
      "Generating post 3/10...\n",
      "Saved: post-003.json\n",
      "Generating post 4/10...\n",
      "Saved: post-004.json\n",
      "Generating post 5/10...\n",
      "Saved: post-005.json\n",
      "Generating post 6/10...\n",
      "Saved: post-006.json\n",
      "Generating post 7/10...\n",
      "Saved: post-007.json\n",
      "Generating post 8/10...\n",
      "Saved: post-008.json\n",
      "Generating post 9/10...\n",
      "Saved: post-009.json\n",
      "Generating post 10/10...\n",
      "Saved: post-010.json\n",
      "All 10 posts generated and saved to experiments/2025_06_19-prompt_v2-inputs_shaw_test-num_posts_10/posts/\n",
      "Running eval: eval_em_dashes\n",
      "Running eval: eval_em_dashes for post: post-004.json\n",
      "Running eval: eval_em_dashes for post: post-008.json\n",
      "Running eval: eval_em_dashes for post: post-009.json\n",
      "Running eval: eval_em_dashes for post: post-005.json\n",
      "Running eval: eval_em_dashes for post: post-002.json\n",
      "Running eval: eval_em_dashes for post: post-003.json\n",
      "Running eval: eval_em_dashes for post: post-001.json\n",
      "Running eval: eval_em_dashes for post: post-006.json\n",
      "Running eval: eval_em_dashes for post: post-010.json\n",
      "Running eval: eval_em_dashes for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v2-inputs_shaw_test-num_posts_10/evals/eval_em_dashes.csv\n",
      "Running eval: eval_voice\n",
      "Running eval: eval_voice for post: post-004.json\n",
      "Running eval: eval_voice for post: post-008.json\n",
      "Running eval: eval_voice for post: post-009.json\n",
      "Running eval: eval_voice for post: post-005.json\n",
      "Running eval: eval_voice for post: post-002.json\n",
      "Running eval: eval_voice for post: post-003.json\n",
      "Running eval: eval_voice for post: post-001.json\n",
      "Running eval: eval_voice for post: post-006.json\n",
      "Running eval: eval_voice for post: post-010.json\n",
      "Running eval: eval_voice for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v2-inputs_shaw_test-num_posts_10/evals/eval_voice.csv\n",
      "Computing results for eval_em_dashes.csv\n",
      "Computing results for eval_voice.csv\n",
      "Results saved to experiments/2025_06_19-prompt_v2-inputs_shaw_test-num_posts_10/results.json\n",
      "Summary saved to summary.csv\n",
      "-------------------------------------------------------------------------\n",
      "Experiment initialized: experiments/2025_06_19-prompt_v3-inputs_shaw_test-num_posts_10\n",
      "\n",
      "Config YAML content:\n",
      "name: 2025_06_19-prompt_v3-inputs_shaw_test-num_posts_10\n",
      "date: '2025-06-19'\n",
      "prompt_name: prompt-v3\n",
      "prompt_path: prompts/ghostwriter/prompt-v3.md\n",
      "model:\n",
      "  name: gpt-4.1-2025-04-14\n",
      "  temperature: 1\n",
      "inputs:\n",
      "  num_posts: 10\n",
      "  total_posts: 10\n",
      "  input_path: data/inputs/inputs-shaw-test.csv\n",
      "evals:\n",
      "  eval_em_dashes:\n",
      "    description: Evaluates the number of em-dashes in a post.\n",
      "    type: code-based\n",
      "    args: null\n",
      "  eval_voice:\n",
      "    description: Evaluates the voice of a LinkedIn post using an LLM Judge.\n",
      "    type: LLM-based\n",
      "    args:\n",
      "      prompt_path: prompts/judge-voice/prompt-v7.md\n",
      "      model_name: gpt-4.1-2025-04-14\n",
      "notes: ''\n",
      "\n",
      "\n",
      " To make changes, edit the config.yaml file directly.\n",
      "Generating post 1/10...\n",
      "Saved: post-001.json\n",
      "Generating post 2/10...\n",
      "Saved: post-002.json\n",
      "Generating post 3/10...\n",
      "Saved: post-003.json\n",
      "Generating post 4/10...\n",
      "Saved: post-004.json\n",
      "Generating post 5/10...\n",
      "Saved: post-005.json\n",
      "Generating post 6/10...\n",
      "Saved: post-006.json\n",
      "Generating post 7/10...\n",
      "Saved: post-007.json\n",
      "Generating post 8/10...\n",
      "Saved: post-008.json\n",
      "Generating post 9/10...\n",
      "Saved: post-009.json\n",
      "Generating post 10/10...\n",
      "Saved: post-010.json\n",
      "All 10 posts generated and saved to experiments/2025_06_19-prompt_v3-inputs_shaw_test-num_posts_10/posts/\n",
      "Running eval: eval_em_dashes\n",
      "Running eval: eval_em_dashes for post: post-004.json\n",
      "Running eval: eval_em_dashes for post: post-008.json\n",
      "Running eval: eval_em_dashes for post: post-009.json\n",
      "Running eval: eval_em_dashes for post: post-005.json\n",
      "Running eval: eval_em_dashes for post: post-002.json\n",
      "Running eval: eval_em_dashes for post: post-003.json\n",
      "Running eval: eval_em_dashes for post: post-001.json\n",
      "Running eval: eval_em_dashes for post: post-006.json\n",
      "Running eval: eval_em_dashes for post: post-010.json\n",
      "Running eval: eval_em_dashes for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v3-inputs_shaw_test-num_posts_10/evals/eval_em_dashes.csv\n",
      "Running eval: eval_voice\n",
      "Running eval: eval_voice for post: post-004.json\n",
      "Running eval: eval_voice for post: post-008.json\n",
      "Running eval: eval_voice for post: post-009.json\n",
      "Running eval: eval_voice for post: post-005.json\n",
      "Running eval: eval_voice for post: post-002.json\n",
      "Running eval: eval_voice for post: post-003.json\n",
      "Running eval: eval_voice for post: post-001.json\n",
      "Running eval: eval_voice for post: post-006.json\n",
      "Running eval: eval_voice for post: post-010.json\n",
      "Running eval: eval_voice for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v3-inputs_shaw_test-num_posts_10/evals/eval_voice.csv\n",
      "Computing results for eval_em_dashes.csv\n",
      "Computing results for eval_voice.csv\n",
      "Results saved to experiments/2025_06_19-prompt_v3-inputs_shaw_test-num_posts_10/results.json\n",
      "Summary saved to summary.csv\n",
      "-------------------------------------------------------------------------\n",
      "Experiment initialized: experiments/2025_06_19-prompt_v4-inputs_shaw_test-num_posts_10\n",
      "\n",
      "Config YAML content:\n",
      "name: 2025_06_19-prompt_v4-inputs_shaw_test-num_posts_10\n",
      "date: '2025-06-19'\n",
      "prompt_name: prompt-v4\n",
      "prompt_path: prompts/ghostwriter/prompt-v4.md\n",
      "model:\n",
      "  name: gpt-4.1-2025-04-14\n",
      "  temperature: 1\n",
      "inputs:\n",
      "  num_posts: 10\n",
      "  total_posts: 10\n",
      "  input_path: data/inputs/inputs-shaw-test.csv\n",
      "evals:\n",
      "  eval_em_dashes:\n",
      "    description: Evaluates the number of em-dashes in a post.\n",
      "    type: code-based\n",
      "    args: null\n",
      "  eval_voice:\n",
      "    description: Evaluates the voice of a LinkedIn post using an LLM Judge.\n",
      "    type: LLM-based\n",
      "    args:\n",
      "      prompt_path: prompts/judge-voice/prompt-v7.md\n",
      "      model_name: gpt-4.1-2025-04-14\n",
      "notes: ''\n",
      "\n",
      "\n",
      " To make changes, edit the config.yaml file directly.\n",
      "Generating post 1/10...\n",
      "Saved: post-001.json\n",
      "Generating post 2/10...\n",
      "Saved: post-002.json\n",
      "Generating post 3/10...\n",
      "Saved: post-003.json\n",
      "Generating post 4/10...\n",
      "Saved: post-004.json\n",
      "Generating post 5/10...\n",
      "Saved: post-005.json\n",
      "Generating post 6/10...\n",
      "Saved: post-006.json\n",
      "Generating post 7/10...\n",
      "Saved: post-007.json\n",
      "Generating post 8/10...\n",
      "Saved: post-008.json\n",
      "Generating post 9/10...\n",
      "Saved: post-009.json\n",
      "Generating post 10/10...\n",
      "Saved: post-010.json\n",
      "All 10 posts generated and saved to experiments/2025_06_19-prompt_v4-inputs_shaw_test-num_posts_10/posts/\n",
      "Running eval: eval_em_dashes\n",
      "Running eval: eval_em_dashes for post: post-004.json\n",
      "Running eval: eval_em_dashes for post: post-008.json\n",
      "Running eval: eval_em_dashes for post: post-009.json\n",
      "Running eval: eval_em_dashes for post: post-005.json\n",
      "Running eval: eval_em_dashes for post: post-002.json\n",
      "Running eval: eval_em_dashes for post: post-003.json\n",
      "Running eval: eval_em_dashes for post: post-001.json\n",
      "Running eval: eval_em_dashes for post: post-006.json\n",
      "Running eval: eval_em_dashes for post: post-010.json\n",
      "Running eval: eval_em_dashes for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v4-inputs_shaw_test-num_posts_10/evals/eval_em_dashes.csv\n",
      "Running eval: eval_voice\n",
      "Running eval: eval_voice for post: post-004.json\n",
      "Running eval: eval_voice for post: post-008.json\n",
      "Running eval: eval_voice for post: post-009.json\n",
      "Running eval: eval_voice for post: post-005.json\n",
      "Running eval: eval_voice for post: post-002.json\n",
      "Running eval: eval_voice for post: post-003.json\n",
      "Running eval: eval_voice for post: post-001.json\n",
      "Running eval: eval_voice for post: post-006.json\n",
      "Running eval: eval_voice for post: post-010.json\n",
      "Running eval: eval_voice for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v4-inputs_shaw_test-num_posts_10/evals/eval_voice.csv\n",
      "Computing results for eval_em_dashes.csv\n",
      "Computing results for eval_voice.csv\n",
      "Results saved to experiments/2025_06_19-prompt_v4-inputs_shaw_test-num_posts_10/results.json\n",
      "Summary saved to summary.csv\n",
      "-------------------------------------------------------------------------\n",
      "Experiment initialized: experiments/2025_06_19-prompt_v5-inputs_shaw_test-num_posts_10\n",
      "\n",
      "Config YAML content:\n",
      "name: 2025_06_19-prompt_v5-inputs_shaw_test-num_posts_10\n",
      "date: '2025-06-19'\n",
      "prompt_name: prompt-v5\n",
      "prompt_path: prompts/ghostwriter/prompt-v5.md\n",
      "model:\n",
      "  name: gpt-4.1-2025-04-14\n",
      "  temperature: 1\n",
      "inputs:\n",
      "  num_posts: 10\n",
      "  total_posts: 10\n",
      "  input_path: data/inputs/inputs-shaw-test.csv\n",
      "evals:\n",
      "  eval_em_dashes:\n",
      "    description: Evaluates the number of em-dashes in a post.\n",
      "    type: code-based\n",
      "    args: null\n",
      "  eval_voice:\n",
      "    description: Evaluates the voice of a LinkedIn post using an LLM Judge.\n",
      "    type: LLM-based\n",
      "    args:\n",
      "      prompt_path: prompts/judge-voice/prompt-v7.md\n",
      "      model_name: gpt-4.1-2025-04-14\n",
      "notes: ''\n",
      "\n",
      "\n",
      " To make changes, edit the config.yaml file directly.\n",
      "Generating post 1/10...\n",
      "Saved: post-001.json\n",
      "Generating post 2/10...\n",
      "Saved: post-002.json\n",
      "Generating post 3/10...\n",
      "Saved: post-003.json\n",
      "Generating post 4/10...\n",
      "Saved: post-004.json\n",
      "Generating post 5/10...\n",
      "Saved: post-005.json\n",
      "Generating post 6/10...\n",
      "Saved: post-006.json\n",
      "Generating post 7/10...\n",
      "Saved: post-007.json\n",
      "Generating post 8/10...\n",
      "Saved: post-008.json\n",
      "Generating post 9/10...\n",
      "Saved: post-009.json\n",
      "Generating post 10/10...\n",
      "Saved: post-010.json\n",
      "All 10 posts generated and saved to experiments/2025_06_19-prompt_v5-inputs_shaw_test-num_posts_10/posts/\n",
      "Running eval: eval_em_dashes\n",
      "Running eval: eval_em_dashes for post: post-004.json\n",
      "Running eval: eval_em_dashes for post: post-008.json\n",
      "Running eval: eval_em_dashes for post: post-009.json\n",
      "Running eval: eval_em_dashes for post: post-005.json\n",
      "Running eval: eval_em_dashes for post: post-002.json\n",
      "Running eval: eval_em_dashes for post: post-003.json\n",
      "Running eval: eval_em_dashes for post: post-001.json\n",
      "Running eval: eval_em_dashes for post: post-006.json\n",
      "Running eval: eval_em_dashes for post: post-010.json\n",
      "Running eval: eval_em_dashes for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v5-inputs_shaw_test-num_posts_10/evals/eval_em_dashes.csv\n",
      "Running eval: eval_voice\n",
      "Running eval: eval_voice for post: post-004.json\n",
      "Running eval: eval_voice for post: post-008.json\n",
      "Running eval: eval_voice for post: post-009.json\n",
      "Running eval: eval_voice for post: post-005.json\n",
      "Running eval: eval_voice for post: post-002.json\n",
      "Running eval: eval_voice for post: post-003.json\n",
      "Running eval: eval_voice for post: post-001.json\n",
      "Running eval: eval_voice for post: post-006.json\n",
      "Running eval: eval_voice for post: post-010.json\n",
      "Running eval: eval_voice for post: post-007.json\n",
      "Results saved to experiments/2025_06_19-prompt_v5-inputs_shaw_test-num_posts_10/evals/eval_voice.csv\n",
      "Computing results for eval_em_dashes.csv\n",
      "Computing results for eval_voice.csv\n",
      "Results saved to experiments/2025_06_19-prompt_v5-inputs_shaw_test-num_posts_10/results.json\n",
      "Summary saved to summary.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prompt_path = f\"prompts/ghostwriter/prompt-v{i+1}.md\"\n",
    "\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "    # create new experiement\n",
    "    experiment_folder = init_experiment(prompt_path, input_path, model_name, num_posts=num_posts)\n",
    "\n",
    "    # generate posts\n",
    "    generate_posts(experiment_folder)\n",
    "\n",
    "    # run evals\n",
    "    run_evals(experiment_folder)\n",
    "\n",
    "    # compute eval results\n",
    "    compute_results(experiment_folder)\n",
    "    \n",
    "    # compute summary\n",
    "    compute_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

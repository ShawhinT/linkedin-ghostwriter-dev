{
  "input": "Share video: Fine-tuning LLMs with MLX",
  "writing_steps": "**Step 1: Purpose & Audience**\n- Purpose: Share a resource/content (video) and highlight its relevance\n- Audience: AI engineers, developers, early-career ML practitioners interested in LLM fine-tuning, especially those curious about MLX or new tooling\n\n**Step 2: Wireframe**\n- Hook about practical fine-tuning, or why MLX matters\n- Mention the video and a quick context on what it covers (fine-tuning LLMs with MLX)\n- Link to the video\n- Focused CTA: invite readers to share their experience or ask for questions for future content\n\n**Step 3: Body** \n- Fine-tuning LLMs is one of the most impactful ways to tailor AI models to your use case. MLX is a new tool making this process more approachable for practitioners. The video linked below walks through the practical steps to fine-tune large language models using MLX. If youâ€™re interested in hands-on, modern LLM workflows, worth checking out.\n\n**Step 4: CTA**\n- What questions do you have about fine-tuning LLMs?\n\n**Step 5A: Hook Directions**\n- [Problem/Solution] \"Fine-tuning LLMs still feels inaccessible to most practitionersâ€”MLX makes it simpler.\"\n- [Trend] \"Fine-tuning is the key to making LLMs actually useful for specific tasks. Hereâ€™s a resource on doing it with MLX.\"\n- [Userâ€™s phrasing] \"Fine-tuning LLMs with MLX\"\n- [Beginner-to-expert] \"If you want hands-on with LLM fine-tuning, this walkthrough with MLX is a great place to start.\"\n- [How-to] \"How to fine-tune LLMs with MLX (video resource)\"\n\n**Step 5B: Direction Notes**\n- Problem/Solution: Barrier to entry, MLX removes friction\n- Trend: Custom LLMs becoming standard, practical guide\n- Beginner-to-expert: Resource lowers the learning curve\n- How-to: Direct, value-forward\n\n**Step 5C: Choose Hook**\n- Iâ€™ll pick the Problem/Solution one for strongest opening.\n\n**Step 6: Draft Post**\n---\nFine-tuning LLMs still feels inaccessible to most practitionersâ€”but the right tooling can change that.\n\nJust found a resource that walks through how to fine-tune large language models using MLX. Itâ€™s a practical step-by-step on using one of the newest tools in the ecosystem, and makes the workflow much more approachable.\n\nCheck out the video here: [video link]\n\nWhat questions do you have about fine-tuning LLMs?\n---\n\n**Step 7: Review for Style, Voice, and Flow**\n- No excessive em dashes.\n- No repeated words/ideas between hook & body.\n- Scannable, clear, action-oriented.\n- Shawâ€™s voice: clear, approachable, practical, focused on helping the reader take next action.\n- Honestâ€”doesnâ€™t assume Shaw has used MLX personally.\n\n**Step 8: Final Post**",
  "final_post": "Fine-tuning LLMs still feels inaccessible to most practitionersâ€”but the right tooling can change that.\n\nHereâ€™s a resource that walks you through how to fine-tune large language models using MLX. If youâ€™re looking for a practical, hands-on workflow using one of the newest tools in the AI ecosystem, this step-by-step video is worth a watch.\n\nðŸŽ¥ Watch here: [video link]\n\nWhat questions do you have about fine-tuning LLMs?"
}